# -*- coding: utf-8 -*-
"""Telecommunications Churn Dataset.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1l4qlwpjfZHkhQRtTKTILsxgnWxyxN7jT
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

#importing data set
df = pd. read_csv("WA_Fn-UseC_-Telco-Customer-Churn.csv")

print("first 5 rows of data set")
df.head()

print(" last 5 rows of data set")
df.tail()

print("Shape of the data set")
df.shape

print("\n Data frame infromation of the data set")
df.info()

print("\n Descriptive Statistics ")
print(df.describe())

print("\nUnique Values per Column")
df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')
for col in df.columns:
    print(f"{col}: {df[col].unique()}")

print(f"\nDataset Shape: {df.shape[0]} rows, {df.shape[1]} columns")
print("\nMissing values per column:")
print(df.isnull().sum())

sns.set(style='whitegrid')

print("\n--- Univariate Analysis ---")

# Step 1 – Target Variable Distribution (Churn)
plt.figure(figsize=(6, 4))
sns.countplot(x='Churn', data=df, palette='Set2')
plt.title('Churn Distribution (0 = No, 1 = Yes)')
plt.xlabel('Churn')
plt.ylabel('Number of Customers')
plt.show()

# Print churn percentage
churn_counts = df['Churn'].value_counts(normalize=True) * 100
print(f"\nChurn Distribution:\n{churn_counts}")
print(f"Churn Rate: {churn_counts[1]:.2f}%")
print("Note: The dataset is imbalanced, which can affect model performance.")

# Step 2 – Categorical Feature Distributions
categorical_cols = [
    'gender', 'SeniorCitizen', 'Partner', 'Dependents', 'PhoneService',
    'MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup',
    'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies',
    'Contract', 'PaperlessBilling', 'PaymentMethod'
]
for col in categorical_cols:
    plt.figure(figsize=(8, 4))
    sns.countplot(x=col, data=df, palette='viridis')
    plt.title(f'Distribution of {col}')
    plt.xlabel(col)
    plt.ylabel('Count')
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.show()

# Step 3 – Numerical Feature Distributions
numerical_cols = ['tenure', 'MonthlyCharges', 'TotalCharges']

for col in numerical_cols:
    plt.figure(figsize=(10, 5))
    sns.histplot(df[col], bins=30, kde=True, color='skyblue')
    plt.title(f'Distribution of {col}')
    plt.xlabel(col)
    plt.ylabel('Number of Customers')
    plt.tight_layout()
    plt.show()

print("\n Bivariate Analysis (Feature vs. Churn) ")
# Step 1: Prepare Churn as numerical for correlation later
df['Churn_num'] = df['Churn'].map({'Yes': 1, 'No': 0})

# Categorical Features vs Churn

print("\n Categorical Features vs. Churn ")

cat_features = ['Contract', 'InternetService', 'PaymentMethod',
                'OnlineSecurity', 'Partner', 'Dependents',
                'PhoneService', 'MultipleLines', 'TechSupport',
                'StreamingTV', 'StreamingMovies']

sns.set(style='whitegrid')
for col in cat_features:
    plt.figure(figsize=(8, 5))
    sns.countplot(x=col, hue='Churn', data=df, palette='pastel')
    plt.title(f'Churn by {col}')
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.show()
     # Churn rate per category
    churn_rate = df.groupby(col)['Churn'].value_counts(normalize=True).unstack() * 100
    print(f"Churn Rate by {col} (%):\n{churn_rate.round(2)}\n")

print("\n Multivariate Analysis")
numerical_columns = ['tenure', 'MonthlyCharges', 'TotalCharges']

# Add Churn as 1 (Yes) and 0 (No) to use it in correlation
df['Churn_num'] = df['Churn'].map({'Yes': 1, 'No': 0})
numerical_columns.append('Churn_num')

# Plot heatmap to see how numbers are related to each other
plt.figure(figsize=(10, 6))
sns.heatmap(df[numerical_columns].corr(), annot=True, cmap='coolwarm')
plt.title('Correlation Between Numerical Columns')
plt.show()
sns.catplot(
    data=df,
    x='Contract',
    hue='InternetService',
    col='Churn',
    kind='count',
    height=5
)

plt.suptitle("Churn by Contract and Internet Type", y=1.05)
plt.tight_layout()
plt.show()

print("\nSummary of Key EDA Findings ")

print("1. Churn Rate: The dataset shows a significant class imbalance with approximately 26% churners.")
print("2. Contract Type: Customers on 'Month-to-month' contracts have a much higher churn rate compared to 'One year' or 'Two year' contracts.")
print("3. Tenure: Customers who churn typically have a much shorter tenure (they are new or not engaged).")
print("4. Internet Service: Customers using 'Fiber optic' internet tend to churn more. This might be due to pricing or service expectations.")
print("5. OnlineSecurity / OnlineBackup / DeviceProtection: Customers without these add-ons churn more — these services might help in customer retention.")
print("6. TotalCharges: New customers with very low or zero total charges (i.e., just joined) are more likely to churn — aligns with low tenure.")
print("7. MonthlyCharges: Higher monthly charges might be slightly related to churn, but more analysis is needed to confirm.")

print("\n--- Initial Hypotheses for Modeling & Strategy ---")

print("1. Customers with month-to-month contracts and no extra services (like security or backup) are more likely to churn.")
print("2. New customers (low tenure and TotalCharges) are at higher risk of churning — they need better onboarding and engagement.")
print("3. Higher monthly charges without enough value might make customers leave — consider pricing vs. value balance.")
print("4. Providing more add-on services might reduce churn by increasing loyalty.")

from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.impute import SimpleImputer

print("\n Data Preparation for Modeling")

# 1. Drop customerID (not useful for prediction)
df_model = df.drop('customerID', axis=1)

# 2. Convert 'Churn' column to 0 and 1 (target variable)
df_model['Churn'] = df_model['Churn'].map({'No': 0, 'Yes': 1})

# 3. Convert 'TotalCharges' to numeric and handle missing values
df_model['TotalCharges'] = pd.to_numeric(df_model['TotalCharges'], errors='coerce')
# Impute missing values in TotalCharges with the mean
imputer = SimpleImputer(strategy='mean')
df_model['TotalCharges'] = imputer.fit_transform(df_model[['TotalCharges']])


# 4. Identify categorical and numerical columns
categorical_cols = df_model.select_dtypes(include='object').columns.tolist()
numerical_cols = df_model.select_dtypes(include=['int64', 'float64']).columns.tolist()
numerical_cols.remove('Churn')  # Don't include target in features


print(f"Categorical Columns: {categorical_cols}")
print(f"Numerical Columns: {numerical_cols}")

# 5. Encode Categorical Columns using LabelEncoder (simple method)
label_encoders = {}

for col in categorical_cols:
    le = LabelEncoder()
    df_model[col] = le.fit_transform(df_model[col])
    label_encoders[col] = le  # Save encoders for future use

# 6. Scale Numerical Columns (StandardScaler = mean 0, std 1)
scaler = StandardScaler()
df_model[numerical_cols] = scaler.fit_transform(df_model[numerical_cols])

print("\n Data is now ready for training")

from sklearn.model_selection import train_test_split
print("\n Splitting Data into Train and Test Sets ")

# 1. Separate Features (X) and Target (y)
X = df_model.drop('Churn', axis=1)
y = df_model['Churn']

# 2. Split the data (80% training, 20% testing)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

print(" Data split completed.")
print(f"Training Set: {X_train.shape[0]} rows")
print(f"Test Set: {X_test.shape[0]} rows")

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report

print("\n Training: Logistic Regression ")

# 1. Initialize & Train Model
lr_model = LogisticRegression()
lr_model.fit(X_train, y_train)

# 2. Make Predictions
y_pred = lr_model.predict(X_test)

# 3. Evaluate Model
print("\n--- Logistic Regression Evaluation ---")
print("Accuracy:", accuracy_score(y_test, y_pred))
print("Precision:", precision_score(y_test, y_pred))
print("Recall:", recall_score(y_test, y_pred))
print("F1 Score:", f1_score(y_test, y_pred))
print("\nConfusion Matrix:\n", confusion_matrix(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))

cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(5,4))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.title("Confusion Matrix - Logistic Regression")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report

print("\n Training: Random Forest Classifier")

# 1. Initialize & Train
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)

# 2. Predict
y_pred_rf = rf_model.predict(X_test)

# 3. Evaluate
print("\n--- Random Forest Evaluation ---")
print("Accuracy:", accuracy_score(y_test, y_pred_rf))
print("Precision:", precision_score(y_test, y_pred_rf))
print("Recall:", recall_score(y_test, y_pred_rf))
print("F1 Score:", f1_score(y_test, y_pred_rf))
print("\nConfusion Matrix:\n", confusion_matrix(y_test, y_pred_rf))
print("\nClassification Report:\n", classification_report(y_test, y_pred_rf))

cm_rf = confusion_matrix(y_test, y_pred_rf)
plt.figure(figsize=(5,4))
sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Greens')
plt.title("Confusion Matrix - Random Forest")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report

print("\n--- Training: XGBoost Classifier ---")

# 1. Initialize & Train Model
xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)
xgb_model.fit(X_train, y_train)

# 2. Predict
y_pred_xgb = xgb_model.predict(X_test)

# 3. Evaluate
print("\n--- XGBoost Evaluation ---")
print("Accuracy:", accuracy_score(y_test, y_pred_xgb))
print("Precision:", precision_score(y_test, y_pred_xgb))
print("Recall:", recall_score(y_test, y_pred_xgb))
print("F1 Score:", f1_score(y_test, y_pred_xgb))
print("\nConfusion Matrix:\n", confusion_matrix(y_test, y_pred_xgb))
print("\nClassification Report:\n", classification_report(y_test, y_pred_xgb))

# Logistic Regression
y_pred_lr = lr_model.predict(X_test)
lr_metrics = {
    'Accuracy': accuracy_score(y_test, y_pred_lr),
    'Precision': precision_score(y_test, y_pred_lr),
    'Recall': recall_score(y_test, y_pred_lr),
    'F1 Score': f1_score(y_test, y_pred_lr)
}

# Random Forest
y_pred_rf = rf_model.predict(X_test)
rf_metrics = {
    'Accuracy': accuracy_score(y_test, y_pred_rf),
    'Precision': precision_score(y_test, y_pred_rf),
    'Recall': recall_score(y_test, y_pred_rf),
    'F1 Score': f1_score(y_test, y_pred_rf)
}

# XGBoost
y_pred_xgb = xgb_model.predict(X_test)
xgb_metrics = {
    'Accuracy': accuracy_score(y_test, y_pred_xgb),
    'Precision': precision_score(y_test, y_pred_xgb),
    'Recall': recall_score(y_test, y_pred_xgb),
    'F1 Score': f1_score(y_test, y_pred_xgb)
}

# Display the comparison
print("\n--- Model Comparison ---")
print("Metric         | Logistic | RandomForest | XGBoost")
print("---------------|----------|--------------|--------")
for metric in ['Accuracy', 'Precision', 'Recall', 'F1 Score']:
    print(f"{metric:<14} | {lr_metrics[metric]:.4f}   | {rf_metrics[metric]:.4f}      | {xgb_metrics[metric]:.4f}")

best_model = xgb_model

# ✅ Save the best model (XGBoost) as model.pkl
import pickle

with open('model.pkl', 'wb') as file:
    pickle.dump(best_model, file)

print("✅ Model saved as model.pkl")